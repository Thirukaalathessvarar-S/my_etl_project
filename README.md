# ETL Workbench - Simple Data Pipeline project

A modern, elegant ETL (Extract, Transform, Load) application built with Flask that enables users to upload CSV files, perform data transformations, and visualize the entire data pipeline process.

<img width="1910" height="898" alt="image" src="https://github.com/user-attachments/assets/844c13c9-2ae1-4d60-a23a-ed23191c93c6" />

<img width="682" height="847" alt="image" src="https://github.com/user-attachments/assets/5e6c705f-ebd6-460c-a570-3070307397d7" />

## âœ¨ Features

- **ğŸ“Š Interactive Data Upload** - Drag & drop or browse to upload CSV files
- **ğŸ”„ Automated ETL Pipeline** - Extract, Transform, and Load data seamlessly
- **ğŸ¯ Data Cleansing** - Intelligent handling of missing values and data quality issues
- **ğŸ“ˆ Visual Pipeline Flow** - Clear visualization of each ETL stage
- **ğŸ“‹ Multi-Stage Display** - View original, transformed, and staged data side-by-side
- **ğŸ“Š Quality Metrics** - Real-time statistics on data processing
- **ğŸ¨ Modern UI** - Clean, professional interface with Rosewood & Misty Rose theme
- **ğŸ“± Responsive Design** - Works beautifully on desktop, tablet, and mobile

## ğŸ› ï¸ Technology Stack

- **Backend:** Python 3.8+, Flask
- **Data Processing:** Pandas
- **Frontend:** HTML5, CSS3, Vanilla JavaScript
- **Database:** SQLite (or your preferred database)

## ğŸ“‹ Prerequisites

Before running this project, make sure you have:

- Python 3.8 or higher
- pip (Python package installer)
- Git (optional, for cloning)

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/Thirukaalathessvarar-S/my_etl_project.git
cd my_etl_project
```

### 2. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the Application

```bash
flask run
```

The application will start at `http://localhost:5000`

## ğŸ“ Project Structure

```
etl-workbench/
â”‚
â”œâ”€â”€ app.py                  # Main Flask application
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ input.csv              # Default sample dataset
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html         # Landing page with upload interface
â”‚   â””â”€â”€ results.html       # Results page showing ETL output
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ (optional assets)
â”‚
â””â”€â”€ README.md              # Project documentation
```

## ğŸ’» Usage

### Running Default ETL

1. Navigate to `http://localhost:5000`
2. Click "Run Demo ETL" to process the default `input.csv`
3. View the results showing all three stages of the pipeline

### Uploading Custom CSV

1. Click "Choose CSV File" or drag & drop your file
2. Click "Process Data" to run the ETL pipeline
3. Review the transformed data and staging results

### Expected CSV Format

Your CSV should have the following structure:

```csv
id,Full Name,value
1,first,100.0
2,second,NaN
3,third,300.0
```

## ğŸ”§ ETL Pipeline Stages

### 1ï¸âƒ£ Extract
- Reads CSV file
- Validates data structure
- Displays original data

### 2ï¸âƒ£ Transform
- Cleans column names (lowercase, underscores)
- Handles missing values (NaN â†’ 0)
- Applies business logic transformations
- Doubles numeric values (example transformation)

### 3ï¸âƒ£ Load
- Appends transformed data to staging table
- Maintains data history
- Displays full staging table

## ğŸ“Š Data Transformations

Current transformations include:

- **Column Renaming:** `Full Name` â†’ `full_name`
- **Null Handling:** `NaN` â†’ `0.0`
- **Value Multiplication:** All values Ã— 2
- **Data Type Validation:** Ensures consistent types

## ğŸ¨ Customization

### Changing Theme Colors

Edit the CSS variables in `templates/index.html` and `templates/results.html`:

```css
/* Current theme: Rosewood & Misty Rose */
--primary-color: #70020F;
--secondary-color: #FFDEE2;
--accent-color: #8B0000;
```

### Adding New Transformations

Edit the transformation logic in `app.py`:

```python
def transform_data(df):
    # Add your custom transformations here
    df = df.fillna(0)
    df['value'] = df['value'] * 2
    return df
```

## ğŸ“ˆ Future Enhancements

- [ ] Export results to CSV/Excel
- [ ] Advanced filtering options
- [ ] Multiple file format support (JSON, XML)
- [ ] Database integration options
- [ ] Scheduled ETL jobs
- [ ] Data validation rules
- [ ] Error logging dashboard
- [ ] API endpoints for programmatic access

## ğŸ› Troubleshooting

### Common Issues

**Issue:** `ModuleNotFoundError: No module named 'flask'`
```bash
pip install flask pandas SQLAlchemy gunicorn
```

**Issue:** Port 5000 already in use
```bash
# Change port in app.py
app.run(debug=True, port=5001)
```

**Issue:** CSV encoding errors
- Ensure CSV is UTF-8 encoded
- Check for special characters

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Thirukaalathessvarar S**
- GitHub: [@yourusername](https://github.com/Thirukaalathessvarar-S/)
- Email: eswar2005s@gmail.com

## ğŸ™ Acknowledgments

- Thanks to the Flask community for excellent documentation
- Pandas library for powerful data manipulation
- Inspiration from modern data engineering practices
